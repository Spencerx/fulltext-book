# Fetch {#fetch}

The `ft_get` function makes it easy to fetch full text articles. There are a few different ways to use `ft_get`:

* Pass in only DOIs - leave `from` parameter `NULL`. This route will first query Crossref API for the publisher of the DOI, then we'll use the appropriate method to fetch full text from the publisher. If a publisher is not found for the DOI, then we'll throw back a message telling you a publisher was not found.
* Pass in DOIs (or other pub IDs) and use the `from` parameter. This route means we don't have to make an extra API call to Crossref (thus, this route is faster) to determine the publisher for each DOI. We go straight to getting full text based on the publisher. 
* Use `ft_search()` to search for articles. Then pass that output to this function, which will use info in that object. This behaves the same as the previous option in that each DOI has publisher info so we know how to get full text for each DOI.

Note that some publishers are available through other data sources, e.g., through Entrez's Pubmed.

`ft_get` is a bit complicated. These are just some of the hurdles we're jumping over:

* Negotiating various user inputs, likely seeing new publishers we've not dealt with
* Dealing with authentication and trying to make it easier for users
* Users sometimes being at an IP address that has access to a publisher and sometimes not
* Caching results to avoid unnecessary downloads if the content has already been acquired

Thus, expect some hiccups here, and please do report problems, and if a certain publisher is not supported yet. 

## Data formats

You can specify whether you want PDF, XML or plaint text with the `type` parameter. It is sometimes ignored, sometimes used, depending on the data source. For certain data sources, they only accept one type. Details by data source/publisher:

- PLOS: pdf and xml
- Entrez: only xml
- eLife: pdf and xml
- Pensoft: pdf and xml
- arXiv: only pdf
- BiorXiv: only pdf
- Elsevier: pdf and plain
- Wiley: only pdf
- Peerj: pdf and xml
- Informa: only pdf
- FrontiersIn: pdf and xml
- Copernicus: pdf and xml
- Scientific Societies: only pdf
- Crossref: depends on the publisher
- other data sources/publishers: there are too many to cover here - will try to make a helper in the future for what is covered by different publishers

## How data is stored

This depends on what `backend` value you use. If you use the default (rds) we store all data in `.rds` files. These are binary compressed files that are specific to R. Because they are specific to R, you don't want to use this option if part of your downstream workflow is using another tool/programming language. 

The three types are stored in differnt ways. xml and plain text are parsed to plain text then stored with whatever backend you choose. However, pdf is retrived as raw bytes and stored as such. Thus, we no longer write pdf files to disk. However, you can easily do that yourself with `ft_extract()` or yourself by using `pdftools::pdf_text` which accepts a file path to a pdf or raw bytes. 

## Usage

```{r}
library(fulltext)
```

List backends available

```{r}
ft_get_ls()
```

The simplest approach is passing a DOI directly to `ft_get`

```{r}
(res <- ft_get('10.1371/journal.pone.0086169'))
res$plos
```

You can pass many DOIs in at once

```{r}
(res <- ft_get(c('10.3389/fphar.2014.00109', '10.3389/feart.2015.00009')))
res$frontiersin
```
